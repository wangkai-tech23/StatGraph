The codes for data processing in Baseline-Model are uploaded in ./Baseline/CarHacking. Here are the steps for our data processing:
1. Data preprocessing and data cleaning: ./Baseline/CarHacking/data_preprocess.py is used to process attack datasets, including DoS_Attack_dataset, Fuzzy_Attack_dataset, Spoofing_the_RPM_gauge_dataset and Spoofing_the_drie_gear_dataset. data_process_normal.py is only used to process normal dataset. You can change the file_path and the new file name in df.to_csv function in the code to preprocess the datasets one by one. Then, it will generate five preprocessed data files respectively. The generated datasets can be found in the compressed file ./Dataset/Car Hacking Dataset/PreprocessedData.rar
2. Image data generating: ./Baseline/CarHacking/dataprocess_to_fig.py is used to process one-dimensional data sequentially into RGB image data. For attack datasets, there are both attack messages and normal messages. So, if an image is composed entirely of normal messages, we will label it as normal image. Otherwise, we will label it as attack image. Therefore, each attack dataset can generate two sets of image. Different directory addresses have been set in image_path_attack and image_path_normal to store the generated normal and attack images. For each set of new generated images, the images will be named from 1 to n (n is the total number of images in the set) by sequence. 
3. Dataset partitioning: The directory we used to store all images is ./baseline/data9_9_3-each27. Then, the later part of ./ Baseline/CarHacking/dataprocess_to_fig.py can help us divide the train set, validation set and the test set from all the image data. Specifically, the ratio of images in training set and validation set for the normal dataset is 8:2. The ratio of images in training set, validation set and test set for the four attack datasets is 7:2:1. All the normal images named by sequence and generated by the attack dataset are modified to ./baseline/data9_9_3-each27/test/0/.
4. Labels saving for IG:
Although the labeling of an image is determined by whether the number of anomalies in the messages that comprise it is not zero, labeling of all data is required for Identification Granularity (IG) detection. For simplicity, since the accuracy of each piece of data is tested only in the test dataset and the normal data does not require the labeling of each piece of data to be recorded, only the labels of attack data need to be recorded. The labels of each data of the attack data image moved to test are stored in test_attack_record in the ./Baseline/CarHacking/dataprocess_to_fig.py and the file IG*.csv is generated to record labels.

